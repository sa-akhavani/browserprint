\section{Methodology}
\label{sec:methodology}

To be able to determine how fingerprintable a browser is, we need to
determine the features it supports when a web page is visited by the
user. Similarly, we need to understand which features are supported by
a specific version because attackers typically target such features in
attacks (e.g., a bug in the video access functionality might be
exploited). Hence, to answer the        research questions we pose in this
study, we need to be able to figure out exactly what features are
supported by each browser version under analysis. In this section, we
describe the methodology we followed in this work, and explain how we
created the datasets we used in our analyses.

\subsection{Feature Gathering}
\label{sec:feature-gathering}

In order to collect \textit{browser feature} sets from Firefox, Opera, and
Chrome, we redirect the browser under analysis to a
JavaScript-instrumented web page. We use the term \textit{feature} to
describe JavaScript objects, methods, and property values built into the
global namespace of the browser's JavaScript implementation (i.e., the
\texttt{window} object).  Clearly, this definition is
JavaScript-centric. However, it is unambiguous and naturally scalable,
as we can automate the collection of features from many different
browser implementations using standard scripting and crawling
techniques. When the instrumented page is loaded by the browser, our
JavaScript is executed.  This code probes and iterates through the
features supported by the browser. This is done by using JavaScript to
traverse the tree of non-cyclic JavaScript object references accessible
from a pristine (i.e., unmodified by polyfills or other prototype-chain
modifications) \texttt{window} object, and collecting the full feature
names encountered during the traversal. Each feature name comprises the
sequence of property names leading from the global object to a given
built-in JavaScript value. The traversal code is careful to not modify
this object (which doubles as the global variable namespace) in any way,
to avoid contaminating the resulting set of feature names. Captured
feature sets are then stored in a database, tagged with identifying
metadata such as the browser's User-Agent string.

We use the terms \textit{browser features}, as defined in this section,
and \textit{JavaScript APIs} interchangeably in our work.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Browser Fingerprinting APIs %%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{fp-apis}

\subsection{Browser Testing Platform}

In this work, we decided to target Google Chrome, Mozilla
Firefox, and Opera browsers as they are well-known, popular browsers that have
millions of users. Firefox possesses a distinct codebase unlike Chrome and Opera
which are both based on Chromium. We gathered a copy of every major Firefox, Chrome, and Opera version that was
released during the March 2016 to April 2020 timeframe (i.e., Chrome
versions 49 to 81, Firefox versions 45 to 75, and Opera versions 36 to 68).

To individually connect each browser version to our instrumented
feature gathering web application, we mainly used the BrowserStack web
service~\cite{browserstack}. BrowserStack is a cloud-based web and mobile testing platform
that enables developers to test their websites and mobile applications
across on a wide range of browsers, operating systems, and real mobile
devices. If a specific browser version or configuration was not
available on BrowserStack, we developed and used automation scripts to
instrument and run the browser instances on a desktop computer running
Windows 10.

% \subsection{Vulnerability Information Gathering}

% One major source of information for security vulnerabilities is the
% CVE (Common Vulnerabilities and Exposures) dataset that is hosted by
% MITRE. A CVE entry contains several fields with standardized
% text/definitions that represent a publicly disclosed cybersecurity
% vulnerabilities and exposures. Each CVE entry has a unique CVE
% identifier, a general description, and several references to one or
% more external information sources of vulnerability.

% For our study, we used the CVE data from the National Vulnerability
% Database (NVD) that is provided by the National Institute of Standards
% and Technology (NIST). For each CVE entry in this dataset, we
% extracted the description, the affected product its specific version
% number, and the severity of the vulnerability. Then, we parsed this
% data and generated a CVE entry list for each browser version in our
% dataset. This new dataset was the basis of the vulnerability and
% feature analysis in this paper.
